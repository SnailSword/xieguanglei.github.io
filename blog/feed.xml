<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title><![CDATA[一叶斋]]></title>
        <description><![CDATA[一叶障目 一叶知秋]]></description>
        <link>http://xieguanglei.github.io/</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 09 May 2019 13:11:11 GMT</lastBuildDate>
        <atom:link href="http://xieguanglei.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Web Worker 详解]]></title>
            <description><![CDATA[<h1 id="web-worker-">Web Worker 详解</h1>
<p>Web Worker（以下简称 Worker）是 JavaScript 多线程编程的解决方案。通过创建一个 Worker，Web 页面（或称「主线程」、「宿主页面」）可以在不阻塞主线程的前提下，执行一些比较费时的任务。在这 2019 年春天，Worker 的浏览器兼容性已经相当好了，但此前我还未有机会（或必要性）在生产环境使用 Worker。前段时间，为了调研 <a href="https://developer.mozilla.org/en-US/docs/Web/API/OffscreenCanvas">OffScreen Canvas</a> 的技术方案，我仔细研究了一下 Worker，不妨记录下来备忘；如果能帮助到读者，即是意外之喜了。</p>
<p><img src="https://img.alicdn.com/tfs/TB1XVooUSrqK1RjSZK9XXXyypXa-1257-282.png" alt=""></p>
<h2 id="messagechannel">MessageChannel</h2>
<p>MessageChannel（消息管道）是用来传递消息的基础类。在浏览器内部，Worker （应该是）继承了 MessageChannel 。看看 MessageChannel 怎么用：</p>
<pre><code class="lang-javascript">const c = new MessageChannel();

c.port1.onmessage = e =&gt; console.log(`port_1 receive: ${e.data}`);
c.port2.onmessage = e =&gt; console.log(`port_2 receive: ${e.data}`);

c.port1.postMessage(&quot;hello from port_1&quot;);
// =&gt; port_2 receive: hello from port_1

c.port2.postMessage(&quot;hello from port_2&quot;);
// =&gt; port_1 receive: hello from port_2
</code></pre>
<p>如上所示，从 <code>port1</code> 发出的消息被 <code>port2</code> 监听到；反之，从 <code>port2</code> 发出的消息也被 <code>port1</code> 监听。在同一个 JavaScript 上下文中，MessageChannel 似乎没有什么存在的必要；而 MessageChannel 的妙处即在于，它可以<strong>跨越不同的 JavaScript 上下文</strong>传输消息。例如，<a href="https://github.com/mdn/dom-examples/tree/master/channel-messaging-basic">这个例子</a>演示了一个 iframe 中的页面是如何与它的宿主页面进行通信的。</p>
<blockquote>
<p>注意，如果在发送消息时，另一个端口（port）上没有监听函数，那么 MessageChannel 会<strong>缓存消息</strong>，直到另一个端口上挂载了监听函数（此时依次收到之前缓存的所有消息）。</p>
</blockquote>
<p>本文所关心的，是 JavaScript 主线程与 Worker， 以及不同 Worker 之间，如何进行通信。</p>
<h2 id="worker-">Worker 基本用法</h2>
<p>通常，需要把主线程代码和 Worker 代码分别写在两个文件中，如下所示：在主线程通过 URL（即 <code>worker-add.js</code>）加载 Worker 代码并创建 Worker。完成创建后，调用 <code>postMessage</code> 方法向 Worker 内发送一个消息，内容（或称消息体）为 JSON 对象 <code>{ a: 1, b: 2 }</code>。然后注册监听函数，将 Worker 返回的消息中的 <code>sum</code> 字段打印出来。</p>
<pre><code class="lang-javascript">// main.js
const worker = new Worker(&#39;worker-add.js&#39;);
worker.postMessage({ a: 1, b: 2 });
worker.onmessage = e =&gt; {
    console.log(`message received: ${e.data.sum}`)
}
</code></pre>
<p>Worker 的 JavaScript 上下文中存在全局对象 <code>self</code>，它代表这个 Worker 的上下文，可以通过向 <code>self</code> 注册 <code>onmessage</code> 函数以监听外部传入的消息。这个例子在收到主线程传来的消息后，将消息体（<code>e.data</code>）的字段 <code>a</code> 和字段 <code>b</code> 相加，并把结果作为字段 <code>sum</code> 发送回主线程：</p>
<pre><code class="lang-javascript">// worker-add.js
self.onmessage = e =&gt; {
    const { a, b } = e.data;
    self.postMessage({ sum: a + b });
};
</code></pre>
<p>这样，整个例子就完成了一次加法运算。主线程将加法的两个参数传入 Worker，Worker 负责进行运算并返回结果，主线程打印出 <code>message received: 3</code>。</p>
<p>如果某个时候，不再需要此 Worker 了，可以调用 <code>worker.terminate()</code> 强制结束 Worker。注意，Worker 中不会有机会进行清理工作。</p>
<h3 id="-worker-">内联 Worker（通过字符串创建）</h3>
<p>有时，因为某些工程上的原因（或者干脆是为了省事儿），有些人也通过包含 Worker 代码的字符串来创建 Worker：将代码字符串转化为 Blob 和 URL，然后再「加载」它。而且，一个常见的实践是，利用「<code>Function.prototype.toString()</code> 恰好返回函数体代码」这一特性来获取包含 Worker 代码的字符串。</p>
<pre><code class="lang-javascript">// 我认为不太合适的做法
function createWorker(workerFuncStr) {
    const src = `(${workerFuncStr})(self);`;
    const blob = new Blob([src], {type: &#39;application/javascript&#39;});
    const url = URL.createObjectURL(blob);
    return new Worker(url);
}

const worker = createWorker(self =&gt; {
    self.onmessage = e =&gt; {
        const { a, b } = e.data;
        self.postMessage({ sum: a + b });
    };
});
</code></pre>
<p>我认为，在比较正式的项目中，应尽量避免使用这种创建 Worker 的方式。例子中的 <code>createWorker</code> 方法令人毫无防备，它容易使我们自然地认为传入的函数会被执行，函数中可访问闭包中的其他变量——可实际上，这个函数只是一段字符串。</p>
<p>Worker 不可避免地会存在依赖，也许 <a href="https://github.com/webpack-contrib/worker-loader">Webpack worker loader</a> 是更好的选择。甚至，可以利用 <a href="https://webpack.js.org/plugins/split-chunks-plugin">SplitChunks 机制</a>与 <a href="https://developer.mozilla.org/en-US/docs/Web/API/WorkerGlobalScope/importScripts"><code>importScript</code></a> 来允许 Worker 与主线程共享某些依赖。</p>
<h3 id="-">初始化参数</h3>
<p>创建 Worker 时，除了 Worker 代码的 URL，还可以传入一些<a href="https://developer.mozilla.org/en-US/docs/Web/API/Worker/Worker#Parameters">参数</a>：</p>
<pre><code class="lang-javascript">new Worker(url, {name: &quot;classic&quot;, credentials: &quot;omit&quot;, name: &quot;worker-1&quot;})
</code></pre>
<ul>
<li><code>type</code>：Worker 的格式类型。默认为 <code>classic</code>，标准里说还可以是 <code>module</code>，估计是预留给浏览器原生模块方案用的。但是经过试验，就连 Chrome 也不支持 <code>module</code>。</li>
<li><code>credentials</code>：来源合法性类型，默认是 <code>omit</code>。目前我还不会有跨域 worker 的需求，所以没有细究。</li>
<li><code>name</code>：名称，默认为空。如果创建 Worker 时指定了名称，那么 Worker 内的上下文 <code>self</code> 上将存在相同值的 <code>name</code> 字段。此参数多少有点用处（或者便利性）吧。</li>
</ul>
<h3 id="worker-">Worker 的上下文</h3>
<p>Worker 的 JavaScript 上下文与主线程的上下文是隔离的。最直白的体现是：Worker 中无法访问 DOM API，无法直接操作宿主页面。宿主页面也无法通过 <code>postMessage</code> 把 DOM API 传递过去。详细地<sup><a href="https://www.html5rocks.com/en/tutorials/workers/basics/">1</a><sup>：</p>
<ul>
<li>Worker 中不支持的操作：<ul>
<li>使用 DOM API。</li>
</ul>
</li>
<li>Worker 中支持的操作：<ul>
<li><code>navigator</code> 和 <code>location</code> 对象（只读）；</li>
<li><code>XMLHttpRequest</code> 对象，用来发起请求；</li>
<li>计时器相关，包括 <code>setTimeout</code> / <code>clearTimeout</code>，<code>setInterval</code> / <code>clearInterval</code> 和 <code>requestAnimationFrame</code> / <code>cancelAnimationFrame</code>；</li>
<li><code>importScripts</code>，引入 Worker 的依赖；</li>
<li><code>Worker</code> 本身，用以在 Worker 中继续创建 Worker。</li>
</ul>
</li>
</ul>
<h2 id="postmessage">PostMessage</h2>
<p>如果不同的线程间不能通信，那么 Worker 的意义将被大大削弱。遵循 <code>MessageChannel</code> 接口，Worker 使用 <code>postMessage</code> 方法与宿主页面或其他 Worker 进行通信。</p>
<p><code>postMessage</code> 可以发送那些能够被 <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm#Supported_types"><strong>结构克隆算法</strong></a>（structured clone algorithm）所克隆的对象。具体地说，包括：</p>
<ul>
<li>除 <code>Symbol</code> 以外的 5 种原始类型变量：数值、字符串、布尔值、<code>undefined</code>、<code>null</code>；</li>
<li><code>Map</code> 和 <code>Set</code> 对象；</li>
<li><code>Date</code> 对象；</li>
<li><code>RegExp</code> 对象；</li>
<li><code>Blob</code> 和 <code>File</code> 对象；</li>
<li><code>ArrayBuffer</code> 和 <code>ArrayBufferView</code> （如 <code>Float32Array</code>，<code>Uint16Array</code> 等）；</li>
<li><code>ImageData</code> 对象；</li>
<li>由以上类型对象组成的 <code>Array</code> 或 <code>Object</code>；换言之，<code>Array</code> 中的项或 <code>Object</code> 中的属性，只能是上述类型的值或对象，一种通俗的说法是 &quot;<strong>plain object</strong>&quot; 或 &quot;<strong>plain array</strong>&quot;。</li>
</ul>
<p>对于 <code>Object</code> 类型的对象，即使其内部存在环状引用，也不影响被发送。</p>
<pre><code class="lang-javascript">// main.js
const o1 = {o2: null}, o2 = {o1: o1};
o1.o2 = o2;
const worker = new Worker(&#39;worker.js&#39;);
worker.postMessage(o1); // OK!

// worker.js 
self.onmessage = e =&gt; {
    const o1 = e.data;
    console.log(o1.o2.o1 === o1); // =&gt; true
};
</code></pre>
<p>最重要的是，Worker 中接收到的数据对象，全部是从主线程发送的消息体中<strong>深度克隆</strong>得来的，两者虽然长得一模一样，事实上却是两个独立的实例，后续即使对其中一个对象进行修改，不会影响到另一个对象。</p>
<pre><code class="lang-javascript">// worker.js
self.onmessage = e =&gt; {
    const obj = e.data;
    obj.val = 2;
    console.log(`worker : obj.val is changed to ${obj.val}`);
    self.postMessage(null);
};

// main.js
const obj = { val: 1 };

const worker = new Worker(&#39;worker.js&#39;);
worker.postMessage(obj);
worker.onmessage = e =&gt; {
    console.log(`main thread : obj.val is still ${obj.val}`);
}

// output
// &gt; worker : obj.val is changed to 2
// &gt; main thread : obj.val is still 1
</code></pre>
<p><img src="https://img.alicdn.com/tfs/TB1xWG2UYvpK1RjSZPiXXbmwXXa-522-350.png" alt=""></p>
<h2 id="-">引用传递</h2>
<p>深度克隆的好处是保护了线程的安全，付出的代价是空间和时间。一些通信发生极为频繁的场景无法承担这样的代价，此时需要以<strong>引用传递</strong>的方式来通信。浏览器中，实现了 <a href="https://developer.mozilla.org/en-US/docs/Web/API/Transferable">Transferable</a> 接口的对象可以被引用传递。具体地，包括 <code>ArrayBuffer</code>，<code>MessagePort</code>，<code>ImageBitmap</code> 和 <code>OffscreenCanvas</code>。</p>
<p>引用传递的本质是共享内存，即传递的是一个指针，内存数据无需发生变化。但是，为了线程安全考虑，当一段数据从源上下文传入目标上下文后，就<strong>无法</strong>在源上下文中再次访问这段内存了：</p>
<pre><code class="lang-javascript">// worker.js
self.onmessage = e =&gt; {
    const buffer = e.data;
    const array = new Float32Array(buffer);
    array[0] = 5, array[2] = 7;
    self.postMessage(buffer, [buffer]);
};

// main.js
const array = new Float32Array([1, 2, 3, 4]);

const worker = new Worker(&#39;/basic-worker.js&#39;);

console.log(`before post : ${array.length} - ${array}`);
worker.postMessage(array.buffer, [array.buffer]);
console.log(`after post : ${array.length}`);

worker.onmessage = e =&gt; {
    const retrArray = new Float32Array(e.data);
    console.log(`after retrieval : ${retrArray.length} - ${retrArray}`)
}

// output : 
// &gt; before post : 4 - 1,2,3,4
// &gt; after post : 0
// &gt; after retrieval : 4 - 5,2,7,4
</code></pre>
<p>上面这个例子，主线程创建了类型化的 32 位浮点数组（<code>Float32Array</code>），其值为 <code>[1.0,2.0,3.0,4.0]</code>。本质上，它是一段 16 字节长的内存（<code>ArrayBuffer</code>），每个 32 位浮点数占 4 个字节。发送之前，我们将其打印出来：<code>before post : 4 - 1,2,3,4</code>。</p>
<p>使用 <code>postMessage</code> 把这段内存数据发送给 Worker：此时，<code>postMessage</code> 接收<strong>两个</strong>参数，形如 <code>worker.postMessage(message, [transfer])</code> 。除了常规的第一个参数 <code>message</code>，还通过第二个参数（为一个数组） <code>[transfer]</code> 来指定「哪些数据需要<strong>传递引用</strong>」这一信息。若不在 <code>[transfer]</code> 中指定，那么这个 <code>buffer</code> 就会像普通的数据那样进行深度克隆。比如，<code>worker.postMessage({b1: buffer1, b2: buffer2}, [buffer2]);</code> 就会对 <code>buffer1</code> 进行深度克隆，而对 <code>buffer2</code> 进行引用传递。</p>
<p>为了线程安全，当一段内存数据被以引用传递的方式发送出去后，在当前上下文就无法再访问了。对类型化数组如 <code>Float32Array</code> 而言，具体的表现是，它会成为一个去势（neutered）的数组（可以理解为成了一个空壳），其长度为 0，此时打印数组的结果是 <code>after post : 0</code>（尝试访问/打印元素将导致抛出异常）。</p>
<p>Worker 线程拿到这段内存，并按照 <code>Float32Array</code> 的格式来解析它。接着，改写其中的值，把第 1 个和第 3 个元素改成 5 和 7，最后同样以引用传递的形式把它发回给主线程。</p>
<p>主线程拿回了这段内存，按照 <code>Float32Array</code> 重新解析这段内存（可以理解给内存套壳，开销很低；注意，之前的壳是不能复用的，需要重新套壳），并将解析得到的数组打印出来，结果是 <code>after retrieval : 4 - 5,2,7,4</code>。可见，数据被 Worker 线程篡改了。</p>
<p><img src="https://img.alicdn.com/tfs/TB18Wi1U4TpK1RjSZR0XXbEwXXa-524-579.png" alt=""></p>
<h2 id="-worker-">多 Worker 间通信</h2>
<p>不仅主线程和 Worker 线程间可以通信，不同的 Worker 之间也可以通信，这是通过 MessageChannel 实现的。<code>MessageChannel</code> 对象上存在两个 成员属性：<code>port1</code> 和 <code>port2</code>，它们均是 <code>MessagePort</code> 对象。<code>MessagePort</code> 也实现了 <code>Transferable</code> 接口，我们可以像传递 <code>ArrayBuffer</code> 那样把 <code>MessagePort</code> 传入 Worker 中：</p>
<pre><code class="lang-javascript">// worker1.js
let port;
const handleInit = (data) =&gt; {
    port = data.port;
};

const handleTransfer = (data) =&gt; {
    port &amp;&amp; port.postMessage({
        type: &#39;TRANSFER&#39;,
        message: data.message + &#39; through worker1;&#39;
    })
};

self.onmessage = function (e) {

    const handleMessage = e.data.type === &#39;INIT&#39; ?
        handleInit : handleTransfer;

    handleMessage(e.data);
}

// worker2.js
self.onmessage = function (e) {
    const port = e.data.port;

    port.onmessage = function (e) {
        self.postMessage({
            type: &#39;TRANSFER&#39;,
            message: e.data.message + &#39; through worker2.&#39;
        });
    }
}

// main.js
const worker1 = new Worker(&quot;worker1.js&quot;);
const worker2 = new Worker(&quot;worker2.js&quot;);

const channel = new MessageChannel();
worker1.postMessage({ type: &#39;INIT&#39;, port: channel.port1 }, [channel.port1]);
worker2.postMessage({ type: &#39;INIT&#39;, port: channel.port2 }, [channel.port2]);

worker1.postMessage({ type: &#39;TRANSFER&#39;, message: &quot;Hello from main thread;&quot; });
worker2.onmessage = function (e) {
    console.log(e.data.message);
}

// output
// &gt; Hello from main thread; through worker1; through worker2.
</code></pre>
<p>上面的例子中，主线程创建了两个 Worker：<code>worker1</code> 和 <code>worker2</code>；然后，创建了 <code>MessageChannel</code> 对象，并将它的 <code>port1</code> 和 <code>port2</code> 分别传递给 <code>worker1</code> 和 <code>worker2</code>。</p>
<p>接着，主线程把将字符串 <code>&quot;Hello from main thread;&quot;</code> 发送给 <code>worker1</code>；<code>worker1</code> 收到此字符串后，加上了 <code>&quot; through worker1;&quot;</code>，并（通过之前传过去的 <code>port1</code>）发送给 <code>worker2</code>；<code>worker2</code> 在收到（从之前传过去的 <code>port2</code> 中监听到）此字符串后，又添加上 <code>&quot; through worker2.&quot;</code>，最后发送给主线程。我们在主线程中打印出最后得到的消息字符串，为 <code>&quot;Hello from main thread; through worker1; through worker2.&quot;</code>。</p>
<p><img src="https://img.alicdn.com/tfs/TB1xOm9U3DqK1RjSZSyXXaxEVXa-684-477.png" alt=""></p>
<p>MessagePort 只能被通过传递引用的方式发送到 Worker 中。与 ArrayBuffer 类似，其被传递到另一个 JavaScript 上下文之后，留在原上下文中的对象便成了空壳，试图调用其上的 <code>postMessage</code> 方法将导致抛出异常。</p>
<h2 id="-worker-">在 Worker 线程中绘图</h2>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/OffscreenCanvas">Offscreen Canvas</a> 的出现使得在 Worker 中进行绘图成为可能。由于 <code>OffScreenCanvas</code> 也实现了 <code>Transferable</code> 接口，主线程能够将 OffScreenCanvas 的引用传递至 Worker 线程。同样，当 offscreenCanvas 被传递到 Worker 中后，留在主线程里的对象便成了空壳，试图调用其上的任何方法都将导致抛出异常。</p>
<pre><code class="lang-javascript">// worker.js
self.onmessage = e =&gt; {
    const canvas = e.data;
    const ctx = canvas.getContext(&#39;2d&#39;);
    ctx.fillStyle = &#39;#FF0000&#39;;
    ctx.fillRect(0, 0, canvas.width, canvas.height);
}

// main.js
const canvas = document.querySelector(&#39;canvas&#39;);
const offscreenCanvas = canvas.transferControlToOffscreen();

const worker = new Worker(&#39;canvas-worker.js&#39;);
worker.postMessage(offscreenCanvas, [offscreenCanvas]);
</code></pre>
<blockquote>
<p>OffScreen（离屏）Canvas 可以被直接创建，也可从普通 Canvas 中创建而来，它的用法不是本文的重点。</p>
</blockquote>
<p>上面这个例子把页面上一个普通的 Canvas 的控制权转交给了离屏 Canvas，然后将离屏 Canvas 以引用传递的方式发送给 Worker。然后，在 Worker 中进行绘制操作，为 Canvas 区域涂满红色。</p>
<h3 id="-">图片加载</h3>
<p>绘图，自然涉及图片资源的加载。传统方式是通过 <code>Image</code> 对象来加载图片以及绘图。然而，Worker 中不存在 <code>Image</code> 对象（也许是因为 <code>Image</code> 过于上层，与 DOM 的关联之处过多），这就需要一种更新、更接近底层的方法来加载图片：通过 <code>fetch</code> 方法直接获取二进制（即 <code>Blob</code> 对象）的图片数据，并转化为 <code>ImageBitmap</code> 对象用以绘图。</p>
<pre><code class="lang-javascript">// worker.js
self.onmessage = e =&gt; {
    const canvas = e.data;
    const ctx = canvas.getContext(&#39;2d&#39;);

    fetch(yourUrl,).then(response =&gt; response.blob())
        .then(blob =&gt; createImageBitmap(blob))
        .then(bitmap =&gt; ctx.drawImage(bitmap, 0, 0));
}
</code></pre>
<p><code>ImageBitmap</code> 是 <code>Image</code> 或 <code>HTMLImageElement</code> 背后的某种存在，或者说是去除了 DOM 功能（如 <code>onload</code>、<code>style</code> 等等）后的 <code>Image</code> ，表示存储 <code>Image</code> 中像素数据的那一块内存区域。在 Canvas 相关的操作中，大部分涉及到 <code>Image</code> 的方法，在接收 <code>Image</code> 参数的时候，也接收 <code>ImageBitmap</code> 对象。如 <a href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage#Parameters">CanvasRenderingContext2D#drawImage</a> 或 <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texImage2D#Parameters">WebGLRenderingContext/texImage2D</a>。同样，ImageBitmap 作为一块内存区域，也可以被以引用传递的方式在 Worker 和主线程间传递。如果绘图操作逻辑需要进一步细粒度的拆分，也许可以利用这一特性来交换绘图过程中产生的中间结果。</p>
<p>注意：OffScreenCanvas 的浏览器兼容性比 Worker 要差很多。</p>
<p><img src="https://img.alicdn.com/tfs/TB1SdvLU4naK1RjSZFtXXbC2VXa-1260-283.png" alt=""></p>
<h2 id="-">小结</h2>
<p>以上即是我对 Web Worker 相关技术进行调研的梳理和总结，记录下来备忘。</p>
]]></description>
            <link>http://xieguanglei.github.io/post/web-worker.html</link>
            <guid isPermaLink="false">web-worker</guid>
            <dc:creator><![CDATA[谢光磊]]></dc:creator>
            <pubDate>Sun, 05 May 2019 00:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[在线学区房地图：一个业余项目]]></title>
            <description><![CDATA[<h1 id="-">在线学区房地图：一个业余项目</h1>
<p>利用周末的时间做了一个 side project，可以在线展示各小学的施教区范围，可作购买学区房之前决策参考之用，非常直观！写篇文章介绍下用法吧，哈哈。</p>
<p>首先界面长成这样，点击 <strong><a href="https://xieguanglei.github.io/schools-map/">直达链接</a></strong> 即可访问。网站是开源的，托管在 <a href="https://github.com/xieguanglei/schools-map">github</a> 上。</p>
<p><img src="http://xieguanglei.oss-cn-hangzhou.aliyuncs.com/blog-post/2019-3-31/1.png" alt=""></p>
<p>数据上目前仅做了杭州的西湖区和滨江区；用户可以在这张地图上直接绘图，然后把绘图数据发 ISSUE 或者 PR 来添加或更新数据。</p>
<h2 id="-">用法</h2>
<h3 id="-">浏览学区划分</h3>
<p>直接进入网站，即可浏览默认区域（杭州市西湖区）的学区房划分。鼠标拖拽（按住左键移动）可平移地图，鼠标滚轮可放大缩小地图。每个学校的学区范围用淡蓝色的多边形覆盖在地图上，可以很直观地看到哪些小区属于这个小学的施教区。</p>
<p>网站可以支持多个区域的数据，可以点击菜单栏中的「区域选择」来选择显示另一个区域的学区划分。（滨江区仅完成了 4 所较热门小学的学区。）</p>
<p><img src="http://xieguanglei.oss-cn-hangzhou.aliyuncs.com/blog-post/2019-3-31/2-o.png" alt=""></p>
<h3 id="-">绘制数据和提交</h3>
<p>用户可以在平台上直接绘制自己关心的学区数据，然后通过 PR 或 issue 选择提交到 github 仓库。绘制需要用到绘制工具栏：</p>
<p><img src="http://xieguanglei.oss-cn-hangzhou.aliyuncs.com/blog-post/2019-3-31/3-o.png" alt=""></p>
<p>四个按钮的作用分别为「绘图」、「撤销」、「导出」、「清除」。</p>
<p>点击「绘图」按钮，会分别提示你输入绘制的区域名称、绘制的学校名称，然后鼠标就会从「手」形变成「十字」形，这提示你可以在地图上进行绘图操作了。</p>
<p><img src="http://xieguanglei.oss-cn-hangzhou.aliyuncs.com/blog-post/2019-3-31/4-o.png" alt=""></p>
<p><img src="http://xieguanglei.oss-cn-hangzhou.aliyuncs.com/blog-post/2019-3-31/5-o.png" alt=""></p>
<p>在地图上依次单击选点，勾勒出学区范围的形状（正在绘图的区块是红色的）；在完成最后一个点时，使用双击表示勾勒绘图操作完成，学区的范围转为蓝色，并附上了包含学校名称的标记。这样，一所学校的施教区就绘制完成了（这里示例中的学区是我随意勾勒的，并不是真实数据）。</p>
<p><img src="http://xieguanglei.oss-cn-hangzhou.aliyuncs.com/blog-post/2019-3-31/6-o.png" alt=""></p>
<p><img src="http://xieguanglei.oss-cn-hangzhou.aliyuncs.com/blog-post/2019-3-31/7-o.png" alt=""></p>
<p>再次点击「绘图」按钮，一所接一所学校地完成其所属学区的绘制操作。如果对绘图结果不满意，可以点击「撤销」按钮取消上一次绘制的内容。绘图过程中关闭页面重新打开，不会丢失已绘制的数据。</p>
<p>点击「导出」按钮将下载一份文本文件，其中包含了你的绘图数据。你可以通过访问 issue 页将此附件提交给我，或者直接通过 PR 来提交数据的更改。</p>
<p><img src="http://xieguanglei.oss-cn-hangzhou.aliyuncs.com/blog-post/2019-3-31/8-o.png" alt=""></p>
<p>点击「清除」按钮即可清空你之前所有的绘图数据。如果你已经完成了提交，或者想要绘制一个新的区域，你需要先清除之前的绘制数据。</p>
<h2 id="-">声明</h2>
<ul>
<li>此地图的学区划分为 Github 上的网友个人整理而成，完全存在划分不准确甚至错误的可能性。本工具提供的信息仅供参考，不承担任何由信息错误导致损失的责任，用户请自行验证信息的真实性。</li>
<li>本工具纯粹为兴趣制作，不产生任何盈利。本地图由 Baidu 地图非商用 SDK 支持。</li>
</ul>
<h2 id="-">感想</h2>
<p>偶尔做做业余项目感觉不错，有种呼吸新鲜空气的感觉。</p>
]]></description>
            <link>http://xieguanglei.github.io/post/schools-map.html</link>
            <guid isPermaLink="false">schools-map</guid>
            <dc:creator><![CDATA[谢光磊]]></dc:creator>
            <pubDate>Sat, 30 Mar 2019 00:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[WebGL 纹理详解]]></title>
            <description><![CDATA[<h1 id="webgl-">WebGL 纹理详解</h1>
<p>Buffer（数据缓冲区）与 Texture（纹理）是 WebGL 程序的两大数据来源。Buffer 可以通过 ArrayBuffer 或更语义化的 TypedArray 来构造；而 Texture 在大多数情况下，是通过 Image 对象来构造的。在构造和使用 Texture 的过程中，需要确定很多<strong>选项</strong>来以不同的方式构造 Texture；这些选项之间有着各种各样的关系，或互相依赖，或互相排斥，或互相影响。最近，我又重新梳理了一遍我所用到的 WebGL 纹理各种参数的影响，稍作整理，以防遗忘。</p>
<p>为此，我专门编写了一个 Demo，如下所示。Demo 页的右上角有一个使用 <a href="https://github.com/dataarts/dat.gui">dat.GUI</a> 生成的控件，其中列举了影响纹理的一些选项。这篇文章将逐个讨论这些选项的作用和相互关系。</p>
<p><a class="jsbin-embed" href="https://jsbin.com/boxazam/latest/embed?output&height=512px">JS Bin on jsbin.com</a></p>
<h2 id="wrap">Wrap</h2>
<p>在 JavaScript 中，创建纹理的基本流程大约如下所示：</p>
<pre><code class="lang-javascript">// 激活纹理单元
gl.activeTexture(...);

// 创建和绑定
const texture = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, texture);

// 参数设置
gl.texParameteri(...);
gl.texParameteri(...);

// 填充纹理的内容
gl.texImage2D(..., image);

// 通过纹理单元将纹理传送给着色器程序
gl.uniform1i(...);
</code></pre>
<p>然后，在着色器中，使用一个坐标 (x,y) 从纹理上取色。</p>
<pre><code class="lang-glsl">vec4 color = texture2D(texture, vec2(x, y));
</code></pre>
<p>通常，从纹理上取色的坐标 x 和 y 的值均在 0~1 之间。Wrap 配置项规定了当取色坐标的坐标取值在 (0, 1) 之外（即试图从纹理图片之外取色）时，应该如何取色。Wrap 有两种：切割(CLAMP)和重复(REPEAT)。我们可以操作上面的 Demo，调整 scale 的值使得纹理图片缩小一些，然后切换 Wrap 配置项为 CLAMP 或 REPEAT，可以发现：当选项置为 CLAMP 时，从纹理外部取色会落到对应的纹理的边缘，比如 <code>texture2D(texture, vec2(2.2, 0.5))</code> 的值会等于 <code>texture2D(texture, vec2(1.0, 0.5))</code>；而选项置为 REPEAT 时，纹理会「平铺」开来，从外部取色会把取色坐标按1取模，映射到纹理内部，比如 <code>texture2D(texture, vec2(2.2, 0.5))</code> 的值会等于 <code>texture2D(texture, vec2(0.2, 0.5))</code>。</p>
<p>切换 Wrap 配置项的代码如下：</p>
<pre><code class="lang-javascript">// CLAMP
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

// REPEAT
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.REPEAT);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.REPEAT);
</code></pre>
<p>下图是 REPEAT 的情况：</p>
<p><img src="https://gw.alicdn.com/tfs/TB1XAx8t9zqK1RjSZPcXXbTepXa-600-380.jpg" alt="repeat"></p>
<p>下图是 CLAMP 的情况：</p>
<p><img src="https://gw.alicdn.com/tfs/TB1dgqbt7voK1RjSZFwXXciCFXa-600-375.jpg" alt="clamp"></p>
<blockquote>
<p>有一点需要注意的是，REPEAT 模式对纹理图片的尺寸有要求，宽度和高度必须为 2 的整数次幂，如 32x32 或 1024x256 的图片都是符合要求的，但 500x512 或 300x300 是不符合的。我们可以将控件中的 size 从 512 改成 300，这时 Demo 将加载这张图片的一个尺寸为 300x300 的替代品作为纹理。如果 Wrap 为 CLAMP，我们会发现稍微纹理模糊了一些，但是如果 Wrap 为 REPEAT，则会报警并黑屏。</p>
</blockquote>
<h2 id="flipy">FlipY</h2>
<p>FlipY 是 WebGL 的一个全局配置项（准确地说，它的名称是 UNPACK_FLIP_Y_WEBGL），在本文的范畴中，它主要影响了 <code>texImage2D()</code> 方法的行为。</p>
<p>按照 OpenGL 的惯例，当着色器调用 <code>texture2D(t, st)</code> 方法从纹理中取色时，传入的取色坐标 <code>st</code> 的原点是左下角。换言之，如果传入的坐标是 (0, 0)，那么 OpenGL 期望取到的是左下角的那个像素的颜色。但是，由于在 Web 上图片数据的存储是从左上角开始的，传入坐标 (0,0) 时，实际上会取到左上角坐标的值。如果我们设置了 <code>FlipY</code> 配置项，那么在向纹理中加载数据的时候，就会对数据作一次翻转，使纹理坐标原点变为左下角。</p>
<p>开启 FlipY 的代码是：</p>
<pre><code class="lang-javascript">gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
</code></pre>
<p>在 Demo 中，默认情况下 FlipY 配置项是勾选的，如果你勾选取消，会发现纹理图片被翻转了。下图是取消 FlipY 配置后的情况。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1dFuJtVzqK1RjSZSgXXcpAVXa-600-379.jpg" alt="cancel-flipY"></p>
<h2 id="min_filter-mag_filter">MIN_FILTER 和 MAG_FILTER</h2>
<p>一个纹理是由离散的数据组成的，比如一个 2x2 的纹理是由 4 个像素组成的，使用 (0,0)、(0, 1) 等四个坐标去纹理上取样，自然可以取到对应的像素颜色；但是，如果使用非整数坐标到这个纹理上去取色。比如，当这个纹理被「拉近」之后，在屏幕上占据了 4x4 一共 16 个像素，那么就会使用 (0.33,0) 之类的坐标去取值，如何根据离散的 4 个像素颜色去计算 (0.33,0) 处的颜色，就取决于参数 MAG_FILTER。在 WebGL 中设置这两个项的代码如下所示：</p>
<pre><code class="lang-javascript">gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
gl.texParameteri(
    gl.TEXTURE_2D, 
    gl.TEXTURE_MIN_FILTER, 
    gl.LINEAR_MIPMAP_LINEAR
);
</code></pre>
<p>MAG_FILTER 有两个可选项，NEAREST 和 LINEAR。顾名思义，NEAREST 就是去取距离当前坐标最近的那个像素的颜色，而 LINEAR 则会根据距离当前坐标最近的 4 个点去内插计算出一个数值，如图所示。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1hgfJt3HqK1RjSZFEXXcGMXXa-600-481.png" alt="MAG_FILTER"></p>
<p>显然 NEAREST 的运行速度更快，但 LINEAR 的效果更好。使用 NEAREST 时，当纹理被拉得比较近，颗粒感会比较明显，而使用 LINEAR 则会顺滑一些。你可以切换右上角空间上的 MAG_FILTER 选项，然后拖动 scale 滑块将纹理放大，体会一下两者的差别。</p>
<p>下图是 MAG_FILTER 为 NEAREST 的效果：</p>
<p><img src="https://gw.alicdn.com/tfs/TB1l_nZtYvpK1RjSZFqXXcXUVXa-600-421.png" alt="MAG_FILTER_NEAREST"></p>
<p>下图是 MAG_FILTER 为 LINEAR 的效果：</p>
<p><img src="https://gw.alicdn.com/tfs/TB1I2_St4TpK1RjSZR0XXbEwXXa-600-419.png" alt="MAG_FILTER_LINEAR"></p>
<p>MAG_FILTER 作用于将纹理拉近/放大的情形，而当纹理远离/缩小的时候，起作用的是 MIN_FILTER。MIN_FILTER 有以下 6 个可选配置项：</p>
<ul>
<li>NEAREST</li>
<li>LINEAR</li>
<li>NEAREST_MIPMAP_NEAREST</li>
<li>NEAREST_MIPMAP_LINEAR</li>
<li>LINEAR_MIPMAP_NEAREST</li>
<li>LINEAR_MIPMAP_LINEAR</li>
</ul>
<p>前两个配置项和 MAG_FILTER 的含义和作用是完全一样的。但问题是，当纹理被缩小时，原纹理中并不是每一个像素周围都会落上采样点，这就导致了某些像素，完全没有参与纹理的计算，新纹理丢失了一些信息。假设一种极端的情况，就是一个纹理彻底缩小为了一个点，那么这个点的值应当是纹理上所有像素颜色的平均值，这才比较合理。但是 NEAREST 只会从纹理中取一个点，而 LINEAR 也只是从纹理中取了四个点计算了一下而已。这时候，就该用上 MIPMAP 了。</p>
<h2 id="mipmap-min_filter">Mipmap 和 MIN_FILTER</h2>
<p>为了在纹理缩小也获得比较好的效果，需要按照采样密度，选择一定数量（通常大于 LINEAR 的 4 个，极端情况下为原纹理上所有像素）的像素进行计算。实时进行计算的开销是很大的，所有有一种称为 MIPMAP（金字塔）的技术。在纹理创建之初，就为纹理创建好 MIPMAP，比如对 512x512 的纹理，依次建立 256x256（称为 1 级 Mipmap）、128x128（称为 2 级 Mipmap） 乃至 2x2、1x1 的纹理。实时渲染时，根据采样密度选择其中的某一级纹理，以此避免运行时的大量计算。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1_0.ot9zqK1RjSZPxXXc4tVXa-501-503.png" alt="Mipmap"></p>
<blockquote>
<p>显而易见的是，使用 MIPMAP 同样需要纹理尺寸为 2 的整数次幂。</p>
</blockquote>
<p>WebGL 中，可以通过调用以下方法来生成 mipmap。</p>
<pre><code class="lang-javascript">gl.generateMipmap(gl.TEXTURE_2D);
</code></pre>
<p>我们将控制面板中的 <code>generateMipmap</code> 打开，并把 scale 调到一个较小的值（比如 0.5），然后切换 MIN_FILTER 的各种设置，就可以观察到 mipmap 的效果了。</p>
<p>下图是 MIN_FILTER 为 LINEAR 的效果（NEAREST 效果是类似的）：</p>
<p><img src="https://gw.alicdn.com/tfs/TB1CmY0tVzqK1RjSZFvXXcB7VXa-600-420.png" alt="MIN_FILTER_LINEAR"></p>
<p>下图是 MIN_FILTER 为 LINEAR_MIPMAP_NEAREST 的效果（LINEAR_MIPMAP_LINEAR 效果是类似的）：</p>
<p><img src="https://gw.alicdn.com/tfs/TB11zLZt9zqK1RjSZPcXXbTepXa-600-418.png" alt="MIN_FILTER_MIPMAP"></p>
<p>可以看到当采用 MIPMAP 时，纹理平滑了很多（特别是头发部分）。</p>
<blockquote>
<p>MIN_FILTER 的默认值是 LINEAR_MIPMAP_NEAREST。在 XXX_MIPMAP_XXX 的格式中，前一个 XXX 表示在单个 MIPMAP 中取色的方式，与单独的 LINEAR 或 NEAREST 类似，而后一个 XXX 表示，随着采样密度连续变化（通常是因为缩放因子连续变化）时，是否在多层 MIPMAP 之间内插。使用 MIPMAP 时，后一个 LINEAR 比较重要，只要后者是 LINEAR，前者的意义其实并不特别大，所以默认选项 NEAREST_MIPMAP_LINEAR 也是最常用的。</p>
</blockquote>
<h2 id="-mipmap">自定义 Mipmap</h2>
<p>我们可以使用 <code>gl.generateMipmap()</code> 方法来根据原始纹理生成一套 mipmap，这种生成的方式是默认的。但是实际上，我们还有一种更灵活的方式来自定义 Mipmap，那就是直接传入另一张图片。比如，这里我们使用的是一张 512x512 的 lena 图，调用 <code>gl.generateMipmap()</code> 会生成 256x256、128x128 直至 1x1 等一系列图片。但是，如果我们手头正好有一张 128x128 尺寸的图片，我们就可以强制指定这张图片作为原始纹理的 1 级 Mipmap。</p>
<p><img src="https://gw.alicdn.com/tfs/TB17fknt9rqK1RjSZK9XXXyypXa-600-503.png" alt="Custom Mipmap"></p>
<p>自定义 Mipmap 纹理的代码如下所示：</p>
<pre><code class="lang-javascript">// 首先要调用此方法
// 如果在 texImage2D 后调用，则定制的 mipmap 会被覆盖
gl.generateTexture(gl.TEXTURE_2D);

gl.texImage2D(
    gl.TEXTURE_2D,
    1,  // 就是这个参数指定几级 Mipmap
    gl.RGBA,
    gl.RGBA,
    gl.UNSIGNED_BYTE,
    image // 尺寸必须严格符合指定级别 Mipmap 应有的尺寸
);
</code></pre>
<p>当我们指定好自定义的 Mipmap 纹理后（即勾选 customMipmap），同时勾选 generateMipmap，并且保证 MIN_FILTER 在 XXX_MIPMAP_XXX 的配置上，此时拖动 scale 滑块，会发现在缩小过程中的某个过程，纹理会变成自定义图片。当 MIN_FILTER 在 XXX_MIPMAP_NEAREST 时，纹理是「突变」的；而当 MIN_FILTER 位于 XXX_MINMAP_LINEAR 时，纹理是「渐变」的，这也印证了前面关于 XXX_MIPMAP_XXX 的解释。</p>
<p>下图是 MIN_FILTER 为 LINEAR_MIPMAP_NEAREST 时缩放的效果：</p>
<p><img src="https://gw.alicdn.com/tfs/TB11r3xt7voK1RjSZFDXXXY3pXa-500-316.gif" alt="CustomMipmap1"></p>
<p>下图是 MIN_FILTER 为 LINEAR_MIPMAP_LINEAR 时缩放的效果：</p>
<p><img src="https://gw.alicdn.com/tfs/TB1ctgvtYvpK1RjSZFqXXcXUVXa-500-316.gif" alt="CustomMipmap2"></p>
<h2 id="srgb-">SRGB 扩展</h2>
<p>RGB 颜色空间是为人眼设计的。但是人眼感光强度和真实光线的物理强度并不是线性关系，这是人眼的生理结构所决定的。比如，在人眼看来，屏幕上显示的白色 #FFFFFF 的亮度，是半灰色 #888888 亮度的 2 倍，但是两者真实的光线物理强度（直射下单位面积上受光照的功率）并不是 2 倍关系。所以，当着色器需要基于一些物理规律来计算颜色时，直接取纹理的颜色没有意义，需要作一次转换。</p>
<p>一个经验是，将人眼感知的颜色归一化到 (0,1) 之间，然后取 2.2 次方幂，得到的结果与光线物理强度是呈线性关系的。如下所示，横轴是 RGB 色彩空间，蓝色直线是人眼的感光曲线，红色曲线是光线物理强度曲线。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1QD7Xt3HqK1RjSZFEXXcGMXXa-297-286.png" alt="SRGB"></p>
<p>SRGB 扩展所做的就是这件事，在用户调用 <code>texImage2D</code> 向纹理中传输数据时，将纹理的每个像素颜色取了自己的 2.2 次方幂。开启 SRGB 扩展的代码如下所示：</p>
<pre><code class="lang-javascript">const SRGBExtension = gl.getExtension(&quot;EXT_SRGB&quot;);

gl.texImage2D(
    gl.TEXTURE_2D, 
    0, 
    // 接下来两个参数原本是 gl.RGBA
    SRGBExtension.SRGB_ALPHA_EXT, 
    SRGBExtension.SRGB_ALPHA_EXT, 
    gl.UNSIGNED_BYTE, 
    image
);
</code></pre>
<p>在控件中勾选 SRGB，会发现纹理变暗了很多，因为颜色作为 [0,1] 之间的数值，取了自己的 2.2 次方幂，自然变小了。其实，如果不使用 SRGB 扩展，在着色器中也可以模拟。我们可以取消勾选 SRGB 选项，然后将 postProcess（后处理）项置为 c^2.2，画面也同样变暗了。postProcess 是这个 Demo 埋在 Shader 中的一个普通 uniform 变量，为最后颜色输出增加一个可选的环节（取自己的 2.2 次方幂，或者取自己的 1/2.2 次方幂）。</p>
<p>着色器中有关 postProcess 的代码如下：</p>
<pre><code class="lang-glsl">if(uPostProcess == 1){
    gl_FragColor = vec4(pow(gl_FragColor.rgb, vec3(1.0/2.2)), 1.0);
}else if(uPostProcess == 2){
    gl_FragColor = vec4(pow(gl_FragColor.rgb, vec3(2.2)), 1.0);
}
</code></pre>
<p>下图是 SRGB 模式的效果，postProcess 选择 c^2.2 能达到同样的效果。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1Aqr8tZbpK1RjSZFyXXX_qFXa-600-419.png" alt="SRGB"></p>
<p>当然，我们也可以勾选 SRGB，然后在 postProcess 中选择取 1/2.2 次方幂，这样输出的颜色和最初的几乎一样。SRGB 扩展将纹理颜色值压低，后处理又把输出的颜色值调亮，两者相互抵消。这正是 PBR 渲染的常用做法，先把纹理颜色从人眼颜色空间的纹理压低成物理空间，然后进行一系列物理规律运算，最后输出时再调亮成人眼颜色空间。</p>
<p>下图是 SRGB + postProcess c^1/2.2 的效果，和不使用 SRGB 和 postProcess 的效果基本一致：</p>
<p><img src="https://gw.alicdn.com/tfs/TB1Qr__tYvpK1RjSZFqXXcXUVXa-600-421.png" alt="SRGB_PostProcess"></p>
<h2 id="tex_lod-">Tex_Lod 扩展</h2>
<p>之前说过，从 Mipmap 中的哪一级纹理取色，取决于在此纹理上采样的密度。但是有了 Tex_Lod 扩展，可以不受此限制，在着色器中直接编码指定从某一级纹理取色。</p>
<p>开启 Tex_Lod 扩展：</p>
<pre><code class="lang-javascript">gl.getExtension(&quot;EXT_shader_texture_lod&quot;);
</code></pre>
<p>着色器中也需要加入开启 #extension 宏：</p>
<pre><code class="lang-glsl">#extension GL_EXT_shader_texture_lod: enable
</code></pre>
<p>在着色器中，可调用 <code>texture2DLodExt</code> 函数来从指定级别的 Mipmap 上取色。</p>
<pre><code class="lang-glsl">gl_FragColor = texture2DLodEXT(uTexture, st, uExtLodLevel);
</code></pre>
<p>在右上角的控制器中，确保 Mipmap 相关的选项都打开，然后打开 extLod，拖动 extLodLevel 滑块，可见虽然纹理本身没有在缩放，但是纹理似乎变模糊了，此时实际上就是取到级别较高的 Mipmap 中去了，因为 Mipmap 的级别越高，像素数量越少，在尺寸不变的情况下，就会变模糊了。</p>
<p>下图是 extLod 开启后，在不依赖纹理的缩放导致采样密度变化的情况下，直接手动编码来从不同级别的 Mipmap 上取色的情况：</p>
<p><img src="https://gw.alicdn.com/tfs/TB1xK7vtVYqK1RjSZLeXXbXppXa-500-316.gif" alt="extLod"></p>
<h2 id="-">小结</h2>
<p>至此，完成了上述所有配置项的讨论。</p>
<p>（完）</p>
<script async src="https://static.jsbin.com/js/embed.min.js?4.1.7"></script>]]></description>
            <link>http://xieguanglei.github.io/post/webgl-texture.html</link>
            <guid isPermaLink="false">webgl-texture</guid>
            <dc:creator><![CDATA[谢光磊]]></dc:creator>
            <pubDate>Tue, 04 Dec 2018 00:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[「译」论孩子]]></title>
            <description><![CDATA[<h1 id="-">「译」论孩子</h1>
<blockquote>
<p>今天在网上闲逛时，无意读到纪伯伦的诗《论孩子》（冰心翻译的版本）。这首诗之前应也曾读过，当时没有什么特别感受；但有了自己的孩子之后，再读此诗，竟有些不一样的感觉。冰心翻译的版本，我觉得有点过于直白，过于追求「直译」了，于是我再对照着英文原文，按着自己的理解意译了一个自己的版本，仅作娱乐。</p>
<p><strong>以下是我的译文：</strong></p>
</blockquote>
<h2 id="-">论孩子</h2>
<p>你的孩子，既是你的孩子，也不是你的孩子。</p>
<p>她是生命的精灵，借你而来，却不因你而来；</p>
<p>她陪伴你于左右，受你养育，却不从属于你。</p>
<p>你可以给予她以关爱，却无法给予她以思想；</p>
<p>你可以庇护她的身体，却不能庇护她的灵魂；</p>
<p>因为她的灵魂，属于明天，那个你在梦中都无法到达的明天。</p>
<p>你可以努力地模仿她，却无法迫使她模仿你，</p>
<p>正如生命时钟不可倒转，昨日时光从未停留。</p>
<p>你是弓，而她是搭在弓弦上的箭矢，</p>
<p>神明已在暗中看清了命运，他用神力拉满弓弦，箭矢便轻快地飞向远方。</p>
<p>愿你与她的缘分，成为生命中一场难忘欢愉，</p>
<p>愿神明眷顾着你，也眷顾着她。</p>
<p>（完）</p>
<blockquote>
<p><strong>附上原文：</strong></p>
<h2 id="on-children">On Children</h2>
<p>Your children are not your children.</p>
<p>They are the sons and daughters of Life’s longing for itself.</p>
<p>They come through you but not from you,</p>
<p>And though they are with you, yet they belong not to you.</p>
<p>You may give them your love but not your thought,</p>
<p>For they have their own thoughts.</p>
<p>You may house their bodies but not their soul,</p>
<p>For their souls dwell in the house of tomorrow,</p>
<p>Which you cannot visit, not even in your dreams.</p>
<p>You may strive to be like them,</p>
<p>But seek not to make them like you,</p>
<p>For life goes not backward nor tarries with yesterday.</p>
<p>You are the bows from which your children,</p>
<p>As living arrows are sent forth.</p>
<p>The archer sees the mark upon the path of the infinite,</p>
<p>And He bends you with His might,</p>
<p>That His arrows may go swift and far.</p>
<p>Let your bending in the archer’s hand be for gladness;</p>
<p>For even as He loves the arrow that flies,</p>
<p>So He loves also the bow that is stable.</p>
<p><strong>附上冰心先生翻译的版本：</strong></p>
<h2 id="-">论孩子</h2>
<p>你们的孩子，都不是你们的孩子，</p>
<p>乃是「生命」为自己所渴望的儿女。</p>
<p>他们是借你们而来，却不是从你们而来，</p>
<p>他们虽和你们同在，却不属于你们。</p>
<p>你们可以给他们以爱，却不可给他们以思想，</p>
<p>因为他们有自己的思想。</p>
<p>你们可以荫庇他们的身体，却不能荫庇他们的灵魂，</p>
<p>因为他们的灵魂，是住在「明日」的宅中，那是你们在梦中也不能想见的。</p>
<p>你们可以努力去模仿他们，却不能使他们来像你们，</p>
<p>因为生命是不倒行的，也不与「昨日」一同停留。</p>
<p>你们是弓，你们的孩子是从弦上发出的生命的箭矢。</p>
<p>那射者在无穷之中看定了目标，也用神力将你们引满，使他的箭矢迅疾而遥远地射了出去。</p>
<p>让你们在射者手中的「弯曲」成为喜乐吧；</p>
<p>因为他爱那飞出的箭，也爱那静止的弓。</p>
</blockquote>
]]></description>
            <link>http://xieguanglei.github.io/post/on-children.html</link>
            <guid isPermaLink="false">on-children</guid>
            <dc:creator><![CDATA[谢光磊]]></dc:creator>
            <pubDate>Fri, 23 Nov 2018 00:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[逐个像素的艺术 —— 2018 iWeb 峰会演讲（全文）]]></title>
            <description><![CDATA[<h1 id="-2018-iweb-">逐个像素的艺术 —— 2018 iWeb 峰会演讲（全文）</h1>
<p><img src="https://gw.alicdn.com/tfs/TB1lboDj3ZC2uNjSZFnXXaxZpXa-800-450.jpg" alt="001"></p>
<p>大家好。很荣幸能够站在这个舞台上。我今天演讲的主题是《逐个像素的艺术》。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1k46zoRnTBKNjSZPfXXbf1XXa-800-450.jpg" alt="002"></p>
<p>先简单作一下自我介绍吧，我来自淘宝网，大家知道阿里巴巴大部分员工都是有花名的，我在公司内的花名是「叶斋」。</p>
<p>我大概从 2013 年开始接触前端图形技术，包括 HTML5 / CSS3 / canvas / webgl 等等，后来我还翻译了一本书，叫《WebGL 编程指南》，如果有学习过原生 WebGL 的，我想应该听说过或者看过这本书吧。</p>
<p>我毕业后，一直在淘宝的前端团队工作，目前负责手机淘宝 App 内部的前端图形渲染基础能力的建设。同时我还维护着一个开源的 WebGL 引擎 G3D。</p>
<p>我的博客，还有邮箱都在这里。如果这次分享之后，大家还有想和我交流的，欢迎给我发邮件。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1ygOco_CWBKNjSZFtXXaC3FXa-800-450.jpg" alt="003"></p>
<p>我读高中的时候，遇到一位音乐老师。他曾经在北朝鲜待过一段时间，所以曾在课上播放过一些北朝鲜的官方大型文艺演出节目的片段。北朝鲜的大型文艺演出有一个特点，就是规模特别大，演出的人很多，但是动作及为整齐，其中最能给我留下深刻印象的，就是「人工大屏」。</p>
<p>什么是「人工大屏」呢？就是有很多很多，估计有上万人，站在类似体育馆看台的台阶上，每个人举一块小牌子，牌子上的颜色各不相同。这样从远处看，这些人就组成了一块显示屏。这块显示屏内容可以跟着演出的节奏进行切换，有时候还可以播放动画，非常整齐。</p>
<p>当时我就想，这演出的背后得，付出多大的代价去训练。因为这种情况，只要有一个人不协调，那就是非常明显的。而要把上万个人训练得没有一个人出错，难度有多高。我觉得，这不是大力出奇迹就能做到的，背后应该有极为严密的组织和极为合理的方法，才能把上万人训练成这样。这是怎么做到的呢？当时我就百思不得其解。直到后来，我学习了 WebGL 和 OpenGL，我才理解到，其实 WebGL 和 OpenGL 所做的事情和训练这么多人是一样的。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1oRGIoGAoBKNjSZSyXXaHAVXa-800-450.jpg" alt="004"></p>
<p>回到这次演讲的题目。我演讲的题目是《逐个像素的艺术》，那什么是像素呢？其实刚刚我说的「人工大屏」，其中每个人其实就是一个像素。单个像素的行为是非常简单的，就是去显示单个颜色。但是，当像素的数量膨胀，达到相当规模的时候，就构成了图像，构成了电影、游戏，呈现了丰富多彩的世界。</p>
<p>而 WebGL / OpenGL 的核心能力，就是「逐个像素地生成颜色」。这里有个误区，就是很多同学一听到 WebGL，第一反应就是，这是用来做 3D，做游戏的。其实呢，WebGL 本身跟 3D 没有太大的关系，它只是提供了「逐像素绘图」的能力，3D 相关的逻辑是更上层的 Shader 层和 JavaScript 层处理的。</p>
<p>我想在场的，大部分是前端程序员，我们可以回想一下，在面向 UI 的编程过程中，我们所操作的最小单元是什么？是一个按钮，一个 input 框，对不对？至于这个按钮，这个 input 框里面的结构是什么样的，这是浏览器本身实现的，我们并没有太多办法去改变。如果我们想要获得像素级别的控制，只能依赖 canvas 标签。</p>
<p>那么熟悉 canvas 的同学可能会说了，canvas 2d 绘图上下文也具有「逐像素绘图」的能力，对不对。我们知道，canvas 2d context 有一个 <code>putImageData</code> 方法。通过这个方法，我们可以去构造一个 UInt16Array，然后向里面填入颜色，每四个值表示一个像素，RGBA。确实，这条路行得通，但是太慢了，一个 100 x 100 的 canvas，这个 canvas 其实尺寸已经很小了。这样一个 canvas 每一帧要循环 100 乘以 100，也就是 10000 次。但是 WebGL 不一样，WebGL 可以利用显卡 GPU 加速的能力，每一个像素的颜色由一个单独的 GPU 核心运算。我们知道 GPU 的核的数量非常多，可以并发进行大量的简单的运算。有个段子，说 GPU 和 CPU 有什么区别，它俩的区别就是 1 个博士生和 1000 个小学生的区别。现在要进行 1000 次简单的四则运算，请问是 1 个博士生算得快，还是 1000 个小学生算得快？那肯定是 1000 个小学生算得快，对吧，因为 1000 个小学生可以进行大量的并发运算。</p>
<p>那么我这次演讲的题目，《逐个像素的艺术》，主要呢就是分享我个人学习、实践 WebGL 的一些心得、体会，以及 WebGL 技术在手机淘宝内部的应用情况。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1ZHF4o5MnBKNjSZFzXXc_qVXa-800-450.jpg" alt="005"></p>
<p>我们看一下 WebGL 在 Google 上的搜索热度趋势。WebGL 差不多 09 年开始有一些草案，11 年标准正式发布，一时间可以说是万众瞩目，可以说那个时候，大家对 WebGL 的期待是很高的，都觉得这技术能够彻底颠覆 Web 的形式。但是呢，随着时间的推移，WebGL 热度，大家可以看到，不仅没升，反而稳中有降。从 11 年到现在这么多年，WebGL 似乎并没有什么里程碑式的产品，更没有像当初大家预期的那样，使 Web 发生翻天覆地的变化。</p>
<p>我们知道前端技术的迭代周期是很快的，逆水行舟，不进则退，如果说 React 的搜索热度趋势和上面这张图差不多的话，那我估计 React 离完蛋不远了。那是不是说，WebGL 就要完蛋了呢？当然不是。否则我也不会站在这里，对吧？</p>
<p><img src="https://gw.alicdn.com/tfs/TB1IGpVo2ImBKNjSZFlXXc43FXa-800-450.jpg" alt="006"></p>
<p>WebGL 并没有完蛋！</p>
<p>首先 WebGL 是一种非常底层的技术，注定了是很慢热的。技术深度比较深，从人才到技术的积累速度都比传统前端技术慢很多，但相对来说技术的过时也会慢很多。</p>
<p>随着无线化的全面到来，PC 由消费产品向生产力工具转变的趋势，我认为这也许会给 WebGL 带来新的机遇。我们知道 WebGL 的功能始终只是 OpenGL ES 的子集，OpenGL ES 又是 OpenGL 的子集，所以 WebGL 在与桌面游戏竞争时，画面效果一直是出于下风的，对游戏来说，画面效果是极为重要的。另一方面，Web 化并未给桌面游戏带来什么太大的好处，为了玩到一个 3A 级大作，比如《巫师3》这种，用户完全有耐心去进行桌面游戏的安装和更新操作，在浏览器里玩对用户来说并没有太大的价值。</p>
<p>但是，生产力工具不一样。随着各类 ERP 系统，特定领域的管理工具（比如家居家装设计，医疗影像等等）从桌面迁移到 Web，WebGL 将会成为这些工具在 Web 上进行图形渲染的唯一选择。而且，生产力工具的图形渲染需求，对画面的要求没有游戏那么高，而迁移到 Web 这件事带来的好处，又会比游戏强很多。</p>
<p>一个明证就是，新一代更加专业的 WebGL 引擎 Babylon.js 的出现，在很多 Web 生产力工具中得到应用。</p>
<p>所以我认为，在今天，WebGL 仍然是值得学习的。</p>
<p>但是我在学习 WebGL 过程中发现，对于没有太多基础的前端工程师而言，入门 WebGL 是一件非常困难的事情。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1C95YoIUrBKNjSZPxXXX00pXa-800-450.jpg" alt="007"></p>
<p>我总结了一下，对一个初学者来说，有三座大山需要去爬。分别是数学基础，渲染管线和状态机，3D 建模知识。下面我简单介绍下：</p>
<p><img src="https://gw.alicdn.com/tfs/TB143X7oY3nBKNjSZFMXXaUSFXa-800-450.jpg" alt="008"></p>
<p>首先是数学基础。不知道在座的各位，高中立体几何有没有全部还给老师。我这里给大家出了一道题。左边我画了一个坐标系，有 X 轴 Y 轴和 Z 轴，然后空间中有一个点 A，从 A 点向几个面和轴作垂线。然后角 AOB 是 45 度，角 BOP 是 30 度，，求 A 点的坐标是多少。</p>
<p>（互动环节，第一个回答上来的同学送一个淘公仔，以下解释答案）。</p>
<p>A 点的坐标是 (0.866, 1, 0.5)，具体是怎么算的呢？AO 是 1.414，也就是 根号2，角 AOB 是 45 度，所以我们知道 AB 和 OB 的场地都是 1，AB 的长度就是坐标 Y 分量的值。然后角 BOP 是 30 度，我们知道 sin(30°) 是 0.5，那么 BP 就是 0.5，OP 是根号3除以2，也就是 0.866。最后的答案是 (0.866, 1, 0.5)。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1IBuWoHwrBKNjSZPcXXXpapXa-800-450.jpg" alt="009"></p>
<p>下面我们来看另一个问题，就是如何描述一个点在空间中的变换，所谓变换就是指平移，旋转和缩放。举个例子，一个点 P 的坐标是 (x, y, z)，平移 (a, b, c)，也就是沿 X 轴平移 a，沿 Y 轴平移 b，沿 Z 轴平移 c，求平移后的点的坐标。</p>
<p>这个问题其实很简单，对吧，答案是 (x+a, y+b, z+c)，方法也很简单，就是简单的矢量加法，各个分量相加就可以。</p>
<p>但是在 WebGL 中，并不是这样计算的，而是像右边这样，使用一个矩阵来计算。首先我们给点的坐标加上一位 1，得到 (x, y, z, 1)，然后使用这样一个矩阵来乘列向量。4 乘 4 的矩阵乘以 4 维列向量的方法，得到一个新的 4 维列向量，每一个值是矩阵的一行乘以列向量得到的单个值。比如，<code>x+a</code> 是这样算出来的：<code>1*a+0*b+0*c+1*1</code>。</p>
<p>我们发现，使用这个矩阵乘下来的结果和之前平移加和的结果是一样的，那这个矩阵就称之为平移矩阵，是不是很神奇？那使用矩阵有什么好处呢？其实啊，除了平移，旋转和缩放也可以统一用矩阵来描述，这样就可以将不同的变换统一为一个格式来描述。而且，当多个变换复合的时候，比如先旋转再平移，我们也可以将旋转矩阵和平移矩阵相乘得到的新矩阵，来描述「先旋转再平移」这么一个复合的变换，非常方便。</p>
<p>那使用矩阵还有一个好处，就是矩阵不仅可以变换位置，还可以变换矢量。上面我们给点 P 的坐标多加了一位 1，如果我们多加的一位是 0，会怎样？加一位 0，表示这个 x,y,z 表示的是一个空间中的一个方向，而不是位置，而平移一个方向，方向本身是不会变的，矩阵乘下来，因为这一位是 0 了，所以也不会变。</p>
<p>熟悉 CSS3 的同学，都知道 CSS3 有个 transform 属性，我们可以使用 translate, rotate 等关键字来描述变换，我想大家应该都用得很溜吧。其实仔细看文档的同学，就会发现还可以使用一个叫 matrix 的关键字来描述变换，这里其实就是使用变换矩阵来描述，这种方式更加直接，实际上浏览器内部也是使用矩阵来描述的。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1nB47oYArBKNjSZFLXXc_dVXa-800-450.jpg" alt="010"></p>
<p>刚刚我举了这俩例子，只是图形学所需要数学知识的冰山一角。当你想要描述旋转的时候，你可能要用到欧拉角，四元数；对模型进行变换的时候，需要考虑是在本地坐标系还是在世界坐标系中进行；相机里也涉及到很多数学知识，包括逆矩阵，不同类型的投影矩阵等等等等。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1uTpyo8smBKNjSZFFXXcT9VXa-800-450.jpg" alt="011"></p>
<p>下面来看第二座大山，渲染管线和 WebGL 状态机。渲染管线这个词不知道大家听说过没有，它是 WebGL 的核心。它提供了一个「友好」的对显卡工作原理的描述，我认为理解了渲染管线，就基本理解了 WebGL 的本质。</p>
<p>这里简单解释一下，举个例子，我要绘制这么一个三角形，那么在 JavaScript 环境中，我们需要构建出一些结构性的数据，来描述这个三角形，其中最重要的就是顶点位置信息，这里三个点 ABC 分别是 1,0,1,3,2,0,0,3,0.5。将这些结构性数据发送给 vertexShader 顶点着色器，顶点着色器是一小段用 glsl 编写的程序，在初始化的时候由 JavaScript 动态编译然后放在渲染管线里面。经过顶点着色器处理，三角形的顶点位置发生了变化，它们会被变换到 CCV 标准立方体中，标准立方体是一个在 X，Y，Z 轴上均在 -1 到 1 的这么一个，边长为 2 的立方体。</p>
<p>然后，数据经过一个名为「光栅化」的过程，三角形就被转化为了屏幕中的一些像素，也就是说这些像素需要被「着色」。</p>
<p>然后再经过片元着色器的处理，片元着色器和顶点着色器一样，也是 JavaScript 初始化的时候放置到渲染管线中的。经过偏远着色器的处理，每一个像素就被「上色」了，最终绘制得到一个红色的三角形。</p>
<p>这里我其实还是讲得比较简单的，还有一些环节（比如深度检测等等）没有涉及。但是呢，如果你能够弄明白渲染管线运行的整个过程，明白 WebGL 的每个 API 究竟是在操作渲染管线的哪个部分，那我觉得啊，你学习 WebGL 已经开始入门了。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1qMd7oY3nBKNjSZFMXXaUSFXa-800-450.jpg" alt="012"></p>
<p>除了渲染管线，你还需要去了解 WebGL 状态机。这么说吧，我们可以把 WebGL 看成是一个大机器，这个机器的产出，就是每一帧生成一张图片，那么这个机器运行需要一些原料，机器上面还有很多开关。通常，机器运行的流程是这样的：</p>
<p>在初始化的时候，我们要准备原料：这些原料包括主要包括着色器程序，数据块，纹理等等。原料的准备是比较耗时的；然后，就开始了每一帧的绘制。我们知道一般来说我们 1 秒钟会渲染 24 帧，如果帧数降低的话，就会给人卡的感觉。</p>
<p>在每一帧，我们做的事情包括，第一步，是去把原料和机器连接起来，这个操作的开销是很低的，大家可以理解为把指针指向原料；第二步，是去操作机器上的各种开关，这些开关可能是离散状态的，就像普通的开关一样，也有可能是需要你输入浮点数，可以把他理解为滑块型的开关；第三部，命令机器，开动起来，也就是去调一次 draw call（drawElements 或者 drawArray）。如此三步，就可以绘制场景中的一部分了。一帧有可能会重复多次上述的流程，最后就这一帧的图像就绘制出来了。</p>
<p>可以看到，每一帧的操作其实性能开销是比较低的，初始化时性能开销很高。那么基本上遵循下面这个原则，就可以让 WebGL 应用保持比较在一个比较好的水平了：首先，不要在每一帧中去处理物料本身；其次，尽可能减少每一帧 drawCall 的次数，当然代价就是初始化构建原料时的复杂度可能会增加。</p>
<p>理解了 WebGL 状态机，再去操作 WebGL API，我相信你就会有种成竹在胸，游刃有余的感觉了。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1QmXhoYorBKNjSZFjXXc_SpXa-800-450.jpg" alt="013"></p>
<p>最后一座大山，是 3D 建模知识。我们不可能始终使用 JavaScript 代码来构建渲染场景需要用到的模型。通常，要借助一些三维建模软件，比如 blender，maya，3d max 甚至 sketchup 等等来。我想如果有志于搞 3D 编程的话，至少学会使用一款 3D 建模软件，进而理解 3D 模型的结构。只有理解 3D 模型的结构，才可能进一步选择合适自己的模型格式。</p>
<p>虽然模型格式有多种多样，比如 obj，stl，fbx，gltf，但是最基本的结构是一致的。举个例子：我有一个模型，就是一个正方形，处于 X-Y 轴这个平面上。它的模型里包含了如下这些信息：一是顶点的坐标，毋庸置疑，这里有四个顶点，所以使用长度为 12 的一个数组来表示；二呢，是法线数据，法线是极为重要的，是光照的基础，这里法线是和顶点一一对应的，都是指向 Z 轴正方向，也就是 (0,0,1)；三是 UV 数据，因为我们这边贴了一张纹理，UV 数据表示顶点与纹理坐标的对应关系，比如 A 这个点对应在纹理图片中是左上角，所以 A 这个点的 UV 是 (0,0)；四是顶点索引数据，因为通常我们是通过绘制三角形来绘制模型，这里的正方形 ABCD 其实是通过绘制两个三角形 ABC 和 ACD 来完成的，索引 [0,1,2,0,2,3] 表示的就是绘制三角形的顺序。当然最后我们还是用到一张图片纹理。以上这些，就是用来表示一个模型最基础的数据结构。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1i0R3oVooBKNjSZFPXXXa2XXa-800-450.jpg" alt="014"></p>
<p>不同的渲染算法，可能会对模型格式提出不同的要求。比如 PBR 渲染（基于物理规则的渲染），就要求模型具有诸如粗糙度，金属度之类的信息。下面是 G3D 渲染的一个经典的 PBR 头盔 demo，这里模型中除了基本的顶点数据，UV 数据，还会使用多张纹理来表示不同的参数，比如基地色；粗糙度/金属度，这里把两个参数合并在了一张纹理的两个通道中；法线，这里法线其实是一个修正量，用来修正跟着顶点的法线，会获得更加细腻的效果；还有发光分量等等。</p>
<p>所以，当我们渲染的物体，材质越来越复杂，算法越来越复杂的时候，实际上模型本身也需要去做出合适的改变。</p>
<p><img src="https://gw.alicdn.com/tfs/TB11JF3oVooBKNjSZFPXXXa2XXa-800-450.jpg" alt="015"></p>
<p>这样，我们就把三座大山全部过完了。除了这三座大山，在入门 WebGL 的过程中，还有一些比较小的门槛，或者说小山坡吧。不过我相信，如果你连前面三座大山都能克服下来，下面这些问题应该不大会阻碍你了。比如说，我们要去熟悉 WebGL 的古怪风格的 API，做任何事情都要先 bind 一下；我们要去学习 GLSL 的语法，这是编写着色器的语言，不过如果你有一些 C 语言基础的话，这应该不是什么难事；比如，我们需要掌握 WebGL 调试的一些方法，尤其是调试 Shader 的一些方法，在 Shader 里面不能 <code>console.log</code>，通常需要一些特殊的技巧把一些中间结果给输出出来；当然，因为 WebGL 项目所需要管理的规模会越来越大，管理的资源的种类可能也会越来越多，所以对前端工程能力也有一定的要求，至少 Webpack 得用得比较溜，各种资源，还有着色器源码的拼接，内联这些工作，都是可以放在编译时来完成的。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1GBqWoHwrBKNjSZPcXXXpapXa-800-450.jpg" alt="016"></p>
<p>当你翻过了这三座大山，也克服了这些小山，你就算精通 WebGL 了吗？我想再给大家泼一盆冷水，其实这时候，也才算是刚刚入门而已。当你掌握了上面这些知识并能熟练运用，你就算是走进了图形渲染技术这座花园的大门，这座花园里有着数不尽的奇珍异宝，你可以自如地把它们拿过来把玩把玩。你可以去更深入地去阅读书籍和文献，去探寻比如水体该如何实现，宝石该如何实现这些一个一个具体又精妙的问题，然后尝试用你手上的工具，WebGL 来实践。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1BM4wo_qWBKNjSZFAXXanSpXa-800-450.jpg" alt="017"></p>
<p>下面讲一讲图形渲染技术在手机淘宝内部的使用，也就是我们团队所做的一些工作。我们团队，是淘宝技术部的终端架构团队，leader 是大家熟悉的 winter 老师。我们团队现在主要是做两个体系，一个是 UI 体系，一个是图形体系。UI 体系主要就是包含 Weex 相关的事情，图形体系主要是 GCanvas 和 G3D。那我们今天分享的主题是 WebGL，所以重点呢是 G3D，但是说到 G3D，不得不提到 GCanvas，而说到 GCanvas 又不得不提到 Weex，那我们就从 Weex 开始说起。</p>
<p>在过去的一年多里，手机淘宝内发生了一个全面 Weex 化的过程。Weex 是淘系应用，包括手机淘宝，手机天猫，里面的一个基础技术框架，Weex 有点类似于 React Native，通过摒弃 WebView 来提高界面渲染的性能和功能。现在大家在手机淘宝里看到的绝大多数页面都已经是 Weex 的了。</p>
<p>但是全面 Weex 化之后，发现了一个问题，就是 Weex 下没有 Canvas 标签。可是使用 Canvas 的需求仍然存在，尤其是遇到营销活动，比如双十一双十二，这时候需求会很多。这时候，我们团队就发展了一个叫做 GCanvas 的产品，目标呢，就是提供一个符合 W3C 标准的 API 的，Weex 环境下的 Canvas。GCanvas 既支持 2d 绘图，也支持 webgl 绘图。</p>
<p>有了 GCanvas 之后呢，我们就像作一些尝试，在 GCanvas 上来渲染一些 3d 场景，一开始我们试着把 babylon.js 等一些已有的 3D 引擎接进来，后来发现行不通，因为这些引擎都依赖了大量的浏览器 API，比如说它会调用 <code>document.createElement</code> 来创建离屏的 canvas 来进行一些预处理，比如它会发起 ajax 请求去加载资源和图片，等等，它的设计和架构就是为浏览器量身定制的。而我们需要的是一个纯粹的，除了 canvas 以外，不依赖其他浏览器 API 的一个渲染引擎。于是我们就写了重新写了一个 3D 引擎，叫 G3D。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1Z8uWoHwrBKNjSZPcXXXpapXa-800-450.jpg" alt="018"></p>
<p>这里我简单地做了一个对比，最左边的是 Web 应用，一般会依赖一个 3D 渲染引擎比如 three.js，babylon.js，由引擎去调用 canvas 的 webgl 绘图上下文，通过浏览器调用系统的图形 API 也就是 OpenGL；而纯 native 的应用，比如手机游戏，一般会用一个大而全的框架，比如 unity，这个框架做的不仅仅是渲染这一层了，还包含很多其他，比如游戏逻辑等等。对于手机淘宝这样的混合型 App，可以依赖一个对标 three.js 的框架，也就是我们的 G3D，然后去调用一个对标 canvas 的 GCanvas，最终还是调用 OpenGL ES。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1DlnJoJcnBKNjSZR0XXcFqFXa-800-450.jpg" alt="019"></p>
<p>看一下 G3D 提供的功能，主要分为四块：底层功能是不以 API 的形式开放给开发者的，包括物料管理，状态机管理，场景树，节点变换等等；基础功能包括相机，元几何体，像立方体，球体，圆柱圆锥等等，不同的光照，不同的材质；交互动画，点选拖拽；最上面是插件功能，主要包含对各种模型的解析，包括解析 OBJ 格式的模型，STL 格式的，字体，还有 GLTF 格式的。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1MftooZj_B1NjSZFHXXaDWpXa-800-450.jpg" alt="020"></p>
<p>这是 G3D 的一些 demo 的演示，分别是透视和正射相机、网格、平行光与点光、元几何体、原始材质 RawMaterial、点选、拖拽、顶点形变动画、PBR 材质、阴影、三种不同的格式模型；最后两个是 PBR 渲染的模型，上面一个是戒指，下面是一个头盔。这个头盔 demo 也是比较经典的用来验证 PBR 渲染的一个案例。</p>
<p><img src="https://gw.alicdn.com/tfs/TB18RqWoHwrBKNjSZPcXXXpapXa-800-450.jpg" alt="021"></p>
<p>下面是 G3D 的系统架构，这个大家看一看就可以了。值得注意的是，G3D 虽然号称完全不依赖浏览器 API，但是实现过程有一些确实是没办法绕过的，比如 Image 和 Video 这样的对象。这里 G3D 是通过依赖注入的方式来完成解耦，就是初始化 G3D 的时候把这些对象注入进 G3D。</p>
<p><img src="https://gw.alicdn.com/tfs/TB1N_lyo8smBKNjSZFFXXcT9VXa-800-450.jpg" alt="022"></p>
<p>这样我的演讲就结束了，谢谢大家！最后，按照惯例要放这个的，就是说：我们招人。</p>
<p>我们是淘宝技术部，终端架构团队，由 winter 老师亲自带领的队伍，负责维护 Weex / Rax / Binding X / GCanvas / G3D 等多个淘系应用中的基础框架，现在跪求：一个是资深前端工程师/专家，一个是资深无线工程师/专家，如果有图形渲染，图像处理等背景，就更好了!</p>
<p>好的，谢谢大家！</p>
<p>（完）</p>
]]></description>
            <link>http://xieguanglei.github.io/post/2018-iweb-speech.html</link>
            <guid isPermaLink="false">2018-iweb-speech</guid>
            <dc:creator><![CDATA[谢光磊]]></dc:creator>
            <pubDate>Sun, 12 Aug 2018 00:00:00 GMT</pubDate>
        </item>
    </channel>
</rss>